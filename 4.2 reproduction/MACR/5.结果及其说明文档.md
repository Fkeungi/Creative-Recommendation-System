## 5. 结果及其说明文档

[TOC]

### 5.0 结果复现任务概述

#### 5.0.1 复现表2：K=20时比较方法的性能评估（RQ1）。

<center>表2：K=20时比较方法的性能评估。Rec是指召回。粗体表示该列中的获胜者。请注意，MACR实现的改进是显著的（p-value<<0.05）</center>

<img src="pics/Table-2.png" alt="Figure-1" style="zoom: 50%;" />

#### 5.0.2 复现图7：MACR_LightGCN和MACR_MF中，c对HR@20的影响（RQ2）

<div><center><img src="pics/Figure-7.png" alt="Figure-1" style="zoom: 60%;" /><br>图7：MACR_LightGCN和MACR_MF中，c对HR@20的影响</center></div>

#### 5.0.3 复现表3：用户分支和项目分支的影响（RQ3）

<center>表3：用户和项目分支对MACR_MF的影响</center>

|                         | HR@20     | Recall@20 | NDCG@20   |
| ----------------------- | --------- | --------- | --------- |
| MACR_MF                 | **0.140** | **0.109** | **0.050** |
| MACR_MF w/o user branch | 0.137     | 0.106     | 0.046     |
| MACR_MF w/o item branch | 0.116     | 0.089     | 0.038     |
| MACR_MF w/o LI          | 0.124     | 0.096     | 0.043     |
| MACR_MF w/o LU          | 0.138     | 0.108     | 0.048     |

#### 5.0.4 复现图8、图9：评价去偏能力，将MACR_MF和MACR_LightGCN与MF和LightGCN进行比较（RQ4）

<div><center><img src="pics/Figure-8.png" alt="Figure-1" style="zoom: 60%;" /><br>图8：LightGCN（MF）和MACR_LightGCN推荐的不同项目组的频率</center></div>

<div><center><img src="pics/Figure-9.png" alt="Figure-1" style="zoom: 60%;" /><br>图9：Adressa上不同商品组的平均商品召回率。</center></div>

#### 5.0.5 复现图10、11：为什么我们的框架有利于推荐中的去偏

<div><center><img src="pics/Figure-10.png" alt="Figure-1" style="zoom: 50%;" /><br>图10：Adressa上不同用户组的平均σ(yu)比较</center></div>

<div><center><img src="pics/Figure-11.png" alt="Figure-1" style="zoom: 50%;" /><br>图11：Adressa上不同项目组的平均σ(yi)比较</center></div>

#### 5.0.6 复现图12：补充实验C.1--不同K的度量

<div><center><img src="pics/Figure-12.png" alt="Figure-1" style="zoom: 50%;" /><br>图12：Adressa数据集上的Top-K推荐性能，通过HR@K, NDCG@K和Recall@K</center></div>

#### 5.0.7 复现表4、表5：补充实验C.2--超参数的影响

<center>表4：α对于MACR_MF的影响</center>

|      | HR@20 | Recall@20 | NDCG@20 |
| ---- | ----- | --------- | ------- |
| 1e-5 | 0.133 | 0.104     | 0.045   |
| 1e-4 | 0.139 | 0.108     | 0.049   |
| 1e-3 | 0.140 | 0.109     | 0.050   |
| 1e-2 | 0.137 | 0.108     | 0.048   |

<center>表5：β对于MACR_MF的影响</center>

|      | HR@20 | Recall@20 | NDCG@20 |
| ---- | ----- | --------- | ------- |
| 1e-5 | 0.139 | 0.108     | 0.049   |
| 1e-4 | 0.139 | 0.109     | 0.049   |
| 1e-3 | 0.140 | 0.109     | 0.050   |
| 1e-2 | 0.139 | 0.108     | 0.049   |

### 5.1 复现表2：K=20时比较方法的性能评估（RQ1）

#### 5.1.1 MF-Adressa

（1）指令：

> python ./macr_mf/train.py --dataset addressa --batch_size 1024 --cuda 0 --saveID 1 --log_interval 10 --lr 0.001 --train normalbce --test normal

（2）结果：

①运行时间：10分钟，best epoch：339

②准确结果：

> addressa dataset best epoch339: hr:0.10526315789473716 ndcg:0.03117746937877148 recall:0.08002735468943604 precision:0.006794258373205733

③粗略结果及其与原文的误差：

粗略结果：HR=0.105，Rec=0.080；NDCG=0.031

原文结果：HR=0.111，Rec=0.085；NDCG=0.034

计算误差：HR -0.006；Rec -0.005；NDCG -0.003

最大误差：<0.01

#### 5.1.2 MACR_MF-Adressa

（1）指令：

> python ./macr_mf/train.py --dataset addressa --batch_size 1024 --cuda 0 --saveID 0 --log_interval 10 --lr 0.001 --check_c 1 --c 40 --train rubibceboth --test rubi --alpha 1e-3 --beta 1e-3 

（2）结果：

①运行时间：10分钟，best epoch：219

②准确结果：

> addressa dataset best epoch219: hr:0.13540669856459364 ndcg:0.04844779112025939 recall:0.10691151750960394 precision:0.009425837320574178

③粗略结果及其与原文的误差：

粗略结果：HR=0.135，Rec=0.107；NDCG=0.048

原文结果：HR=0.140，Rec=0.109；NDCG=0.050

计算误差：HR -0.005；Rec -0.002；NDCG -0.002

最大误差：<0.01

#### 5.1.3 MACR_MF-Gowalla

（1）指令：

> python ./macr_mf/train.py --dataset gowalla --batch_size 4096 --cuda 0 --saveID 0 --log_interval 10 --lr 0.001 --check_c 1 --c 40 --train rubibceboth --test rubi --alpha 1e-2 --beta 1e-3

（2）结果：

①运行时间：180分钟，best epoch：349

②准确结果：

> gowalla dataset best epoch349: hr:0.2667271784232356 ndcg:0.05738695245085963 recall:0.08371401928767233 precision:0.026637059128630614

③粗略结果及其与原文的误差：

粗略结果：HR=0.267；Rec=0.083；NDCG=0.057

原文结果：HR=0.252，Rec=0.077；NDCG=0.050

计算误差：HR +0.015；Rec +0.006；NDCG +0.007

最大误差：<0.02

#### 5.1.4 LightGCN-Adressa

（1）指令：

> python macr_lightgcn/LightGCN.py --data_path data/ --dataset addressa --verbose 1 --layer_size [64,64] --Ks [20] --loss bce --test normal --epoch 2000 --early_stop 1 --lr 0.001 --batch_size 1024 --gpu_id 1 --log_interval 10

（2）结果：

①运行时间：120分钟，epoch：380

②准确结果：

> Epoch 380 [23.5s + 0.5s]: test==[6.83245=6.82665 + 0.00580 + 0.00000], recall=[0.09810], hr=[0.12392], ndcg=[0.04059]
> Early stopping is trigger at step: 10 log:0.12392344325780869

③粗略结果及其与原文的误差：

粗略结果：HR=0.124；Rec=0.098；NDCG=0.041

原文结果：HR=0.123，Rec=0.098；NDCG=0.040

计算误差：HR +0.001；Rec +0.000；NDCG +0.001

最大误差：<0.001

#### 5.1.5 MACR_LightGCN-Adressa

（1）指令：

> python macr_lightgcn/LightGCN.py --data_path data/ --dataset addressa --verbose 1 --layer_size [64,64] --Ks [20] --loss bceboth --test rubiboth --c 40 --epoch 2000 --early_stop 1 --lr 0.001 --batch_size 1024 --gpu_id 0 --log_interval 10 --alpha 1e-2 --beta 1e-3

（2）结果：

①运行时间：20分钟，epoch：320

②准确结果：

> Epoch 320
> c:40.00 recall=[0.12118, 0.12118], hit=[0.14976, 0.14976], ndcg=[0.05613, 0.05613]
> Early stopping is trigger at step: 10 log:0.14976076781749725

③粗略结果及其与原文的误差：

粗略结果：HR=0.150；Rec=0.121；NDCG=0.056

原文结果：HR=0.158，Rec=0.127；NDCG=0.052

计算误差：HR -0.008；Rec -0.006；NDCG +0.004

最大误差：<0.01

### 5.2 复现图7：MACR_LightGCN和MACR_MF中，c对HR@20的影响（RQ2）

<div><center><img src="pics/Figure-7.png" alt="Figure-1" style="zoom: 60%;" /><br>图7：MACR_LightGCN和MACR_MF中，c对HR@20的影响</center></div>

表格中值的含义：{MACR_LightGCN，MACR_MF}

训练参数：--alpha 1e-3 --beta 1e-3

| c(best epoch)\HR@20 | 运行结果      | 原文结果      | 计算误差        |
| ------------------- | ------------- | ------------- | --------------- |
| 0{490}              | {0.121}       | {0.126}       | {-0.005}        |
| 10{470}             | {0.128}       | {0.133}       | {-0.005}        |
| 20{420}             | {0.137}       | {0.144}       | {-0.007}        |
| 30{370}             | {0.142}       | {0.157}       | {-0.015}        |
| 40{320,219}？       | {0.150,0.135} | {0.158,0.140} | {-0.008,-0.005} |
| 50                  |               |               |                 |
| 60                  |               |               |                 |

### 5.6 复现图12：补充实验C.1--不同K的度量

<div><center><img src="pics/Figure-12.png" alt="Figure-1" style="zoom: 50%;" /><br>图12：Adressa数据集上的Top-K推荐性能，通过HR@K, NDCG@K和Recall@K</center></div>

（1）指令：

> python ./macr_mf/train.py --dataset addressa --batch_size 1024 --cuda 0 --saveID 1 --log_interval 10 --lr 0.001 --train normalbce --test normal --Ks[20]

修改 --Ks[20] 的值以进行不同参数的测试。

（2）结果：

表格中值的含义：{MF，LightGCN，MACR_MF，MACR_LightGCN}

原文结果为估算值。

| K(best epoch)                   | HR@K                          | NDCG@K                        | Recall@K                      |
| ------------------------------- | ----------------------------- | ----------------------------- | ----------------------------- |
| **1-运行结果**{229,190,369,340} | {0.008,0.009,0.018,0.020}     | {0.008,0.009,0.018,0.020}     | {0.005,0.005,0.010,0.013}     |
| 1-原文结果                      | {0.006,0.010,0.016,0.018}     | {0.006,0.010,0.016,0.018}     | {0.004,0.005,0.010,0.010}     |
| 1-计算误差                      | {+0.002,-0.001,+0.002,+0.002} | {+0.002,-0.001,+0.002,+0.002} | {+0.001,+0.000,+0.000,+0.003} |
| **5-运行结果**{279}             | {0.037}                       | {0.017}                       | {0.026}                       |
| 5-原文结果                      | {0.037}                       | {0.015}                       | {0.026}                       |
| 5-计算误差                      | {+0.000}                      | {+0.002}                      | {+0.000}                      |
| **10-运行结果**{309}            | {0.062}                       | {0.022}                       | {0.044}                       |
| 10-原文结果                     | {0.062}                       | {0.022}                       | {0.042}                       |
| 10-计算误差                     | {+0.000}                      | {+0.000}                      | {+0.002}                      |
| **15-运行结果**{579}            | {0.090}                       | {0.031}                       | {0.067}                       |
| 15-原文结果                     | {0.085}                       | {0.028}                       | {0.067}                       |
| 15-计算误差                     | {+0.005}                      | {+0.003}                      | {+0.000}                      |
| **20-运行结果**{339}            | {0.105}                       | {0.031}                       | {0.080}                       |
| 20-原文结果                     | {0.105}                       | {0.031}                       | {0.082}                       |
| 20-计算误差                     | {+0.000}                      | {+0.000}                      | {-0.002}                      |

### 5.7 复现表4、表5：补充实验C.2--超参数的影响

（1）指令：

> python ./macr_mf/train.py --dataset addressa --batch_size 1024 --cuda 0 --saveID 0 --log_interval 10 --lr 0.001 --check_c 1 --c 40 --train rubibceboth --test rubi --alpha 1e-3 --beta 1e-3 --Ks [20]

修改 --alpha 1e-3 --beta 1e-3 的值以进行不同参数的测试。

注：在典型的Adressa数据集上进行了MACR_MF的实验 $\alpha$ 和 $\beta$ 分别地特别地，我们在{1e-5，1e-4，1e-3，1e-2}的范围内搜索它们的值。当改变一个参数时，另一个参数被设置为常数1e-3。

> [-h] [--data_path [DATA_PATH]] [--dataset [DATASET]] [--source [SOURCE]] [--train [TRAIN]] [--test [TEST]] [--valid_set [VALID_SET]]     
>                 [--alpha ALPHA] [--beta BETA] [--early_stop EARLY_STOP] [--verbose VERBOSE] [--epoch EPOCH] [--embed_size EMBED_SIZE]
>                 [--batch_size BATCH_SIZE] [--Ks [KS]] [--epochs [EPOCHS]] [--regs REGS] [--c C] [--train_c TRAIN_C] [--lr LR] [--wd WD]
>                 [--model [MODEL]] [--skew SKEW] [--devide_ratio DEVIDE_RATIO] [--save_flag SAVE_FLAG] [--cuda CUDA] [--pretrain PRETRAIN]
>                 [--check_c CHECK_C] [--log_interval LOG_INTERVAL] [--pop_wd POP_WD] [--base BASE] [--cf_pen CF_PEN] [--saveID [SAVEID]]
>                 [--user_min USER_MIN] [--user_max USER_MAX] [--data_type [DATA_TYPE]] [--imb_type [IMB_TYPE]] [--top_ratio TOP_RATIO] [--lam LAM]        
>                 [--check_epoch [CHECK_EPOCH]] [--start START] [--end END] [--step STEP] [--out OUT]

（2）结果：

<center>表4：α对于MACR_MF的影响，运行结果(原文结果)[计算误差]</center>

| 参数值(best epoch) | HR@20                | Recall@20            | NDCG@20              |
| ------------------ | -------------------- | -------------------- | -------------------- |
| 1e-5(149)          | 0.106(0.133)[-0.027] | 0.083(0.104)[-0.021] | 0.033(0.045)[-0.012] |
| 1e-4(149)          | 0.128(0.139)[-0.011] | 0.099(0.108)[-0.009] | 0.040(0.049)[-0.009] |
| 1e-3(219)          | 0.135(0.140)[-0.005] | 0.107(0.109)[-0.002] | 0.048(0.050)[-0.002] |
| 1e-2(139)          | 0.129(0.137)[-0.008] | 0.102(0.108)[-0.006] | 0.048(0.048)[+0.000] |

<center>表5：β对于MACR_MF的影响，运行结果(原文结果)[计算误差]</center>

| 参数值(best epoch) | HR@20                | Recall@20            | NDCG@20              |
| ------------------ | -------------------- | -------------------- | -------------------- |
| 1e-5(239)          | 0.139(0.139)[+0.000] | 0.107(0.108)[-0.001] | 0.047(0.049)[-0.002] |
| 1e-4(239)          | 0.138(0.139)[-0.001] | 0.106(0.109)[-0.003] | 0.047(0.049)[-0.002] |
| 1e-3(219)          | 0.135(0.140)[-0.005] | 0.107(0.109)[-0.002] | 0.048(0.050)[-0.002] |
| 1e-2(159)          | 0.135(0.139)[-0.004] | 0.107(0.108)[-0.001] | 0.043(0.049)[-0.006] |